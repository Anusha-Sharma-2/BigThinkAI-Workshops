# Reinforcement Learning + GRPO Workshop

In this workshop, we explore Reinforcement Learning techniques to fine-tune Microsoft's 14B parameter LLM (Phi-4) for improved mathematical reasoning using the Group Relative Policy Optimization (GRPO) algorithm.

The project walks through end-to-end training using Unslothâ€™s PatchFastRL and LoRA for memory-efficient optimization, while focusing on interpretability and reward-based fine-tuning using math problem datasets.

---

## What It Covers
- **Reinforcement Learning (RL) Fundamentals**  
  Agents, Actions, Rewards, Value & Policy Networks
- **GRPO (Group Relative Policy Optimization)**  
  GRPO vs PPO, KL divergence penalty, Policy Gradients
- **Unsloth + PatchFastRL**  
  Accelerated RL patching for language models
- **Low-Rank Adaptation (LoRA)**  
  Lightweight fine-tuning for large models
- **gsm8k Dataset & Reward Functions**  
  Data prep, structured reasoning formats, reward shaping
